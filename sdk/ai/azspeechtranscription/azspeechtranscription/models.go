// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License. See License.txt in the project root for license information.
// Code generated by Microsoft (R) Go Code Generator. DO NOT EDIT.

package azspeechtranscription

import "github.com/Azure/azure-sdk-for-go/sdk/azcore/streaming"

// ChannelCombinedPhrases - The full transcript per channel.
type ChannelCombinedPhrases struct {
	// REQUIRED; The complete transcribed text for the channel.
	Text *string

	// The 0-based channel index. Only present if channel separation is enabled.
	Channel *int32
}

type TranscribeRequest struct {
	// REQUIRED; The content of the audio file to be transcribed. The audio file must be shorter than 2 hours in audio duration
	// and smaller than 250 MB in size.
	Audio streaming.MultipartContent

	// Metadata for a transcription request. This field contains a JSON-serialized object of type `TranscribeDefinition`.
	Options *TranscriptionOptions
}

// TranscribedPhrase - A transcribed phrase.
type TranscribedPhrase struct {
	// REQUIRED; The confidence value for the phrase.
	Confidence *float32

	// REQUIRED; The duration of the phrase in milliseconds.
	DurationMilliseconds *int32

	// REQUIRED; The start offset of the phrase in milliseconds.
	OffsetMilliseconds *int32

	// REQUIRED; The transcribed text of the phrase.
	Text *string

	// The 0-based channel index. Only present if channel separation is enabled.
	Channel *int32

	// The locale of the phrase.
	Locale *string

	// A unique integer number that is assigned to each speaker detected in the audio without particular order. Only present if
	// speaker diarization is enabled.
	Speaker *int32

	// The words that make up the phrase. Only present if word-level timestamps are enabled.
	Words []*TranscribedWord
}

// TranscribedWord - Time-stamped word in the display form.
type TranscribedWord struct {
	// REQUIRED; The duration of the word in milliseconds.
	DurationMilliseconds *int32

	// REQUIRED; The start offset of the word in milliseconds.
	OffsetMilliseconds *int32

	// REQUIRED; The recognized word, including punctuation.
	Text *string
}

// TranscriptionDiarizationOptions - The Speaker Identification settings. Diarization settings must be specified to enable
// speaker identification.
type TranscriptionDiarizationOptions struct {
	// Gets or sets a value indicating whether speaker diarization is enabled.
	Enabled *bool

	// Gets or sets a hint for the maximum number of speakers for diarization. Must be greater than 1 and less than 36.
	MaxSpeakers *int32
}

// TranscriptionOptions - Metadata for a transcription request.
type TranscriptionOptions struct {
	// The 0-based indices of the channels to be transcribed separately. If not specified, multiple channels are merged and transcribed
	// jointly. Only up to two channels are supported.
	ActiveChannels []*int32

	// Mode of diarization.
	DiarizationOptions *TranscriptionDiarizationOptions

	// A list of possible locales for the transcription. If not specified, the locale of the speech in the audio is detected automatically
	// from all supported locales.
	Locales []*string

	// Maps some or all candidate locales to a model URI to be used for transcription. If no mapping is given, the default model
	// for the locale is used.
	Models map[string]*string

	// Mode of profanity filtering.
	ProfanityFilterMode *ProfanityFilterMode
}

// TranscriptionResult - The result of the transcribe operation.
type TranscriptionResult struct {
	// REQUIRED; The full transcript for each channel.
	CombinedPhrases []*ChannelCombinedPhrases

	// REQUIRED; The duration of the audio in milliseconds.
	DurationMilliseconds *int32

	// REQUIRED; The transcription results segmented into phrases.
	Phrases []*TranscribedPhrase
}
